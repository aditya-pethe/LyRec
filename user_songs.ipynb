{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Joining our data\n",
    "\n",
    "Our data was obtained through 3 seperate csv files, so we need to join them all together   \n",
    "We start by reading the in dataframe containing user_id, song_id, and listen counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>song_id</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOAKIMP12A8C130995</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOAPDEY12A81C210A9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOBBMDR12A8C13253B</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOBFNSP12AF72A0E22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOBFOVM12A58A7D494</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48373581</th>\n",
       "      <td>b7815dbb206eb2831ce0fe040d0aa537e2e800f7</td>\n",
       "      <td>SOUHHHH12AF729E4AF</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48373582</th>\n",
       "      <td>b7815dbb206eb2831ce0fe040d0aa537e2e800f7</td>\n",
       "      <td>SOUJVIT12A8C1451C1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48373583</th>\n",
       "      <td>b7815dbb206eb2831ce0fe040d0aa537e2e800f7</td>\n",
       "      <td>SOUSMXX12AB0185C24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48373584</th>\n",
       "      <td>b7815dbb206eb2831ce0fe040d0aa537e2e800f7</td>\n",
       "      <td>SOWYSKH12AF72A303A</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48373585</th>\n",
       "      <td>b7815dbb206eb2831ce0fe040d0aa537e2e800f7</td>\n",
       "      <td>SOYYFLV12A58A7A88F</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48373586 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           user_id             song_id  count\n",
       "0         b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOAKIMP12A8C130995      1\n",
       "1         b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOAPDEY12A81C210A9      1\n",
       "2         b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBBMDR12A8C13253B      2\n",
       "3         b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBFNSP12AF72A0E22      1\n",
       "4         b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBFOVM12A58A7D494      1\n",
       "...                                            ...                 ...    ...\n",
       "48373581  b7815dbb206eb2831ce0fe040d0aa537e2e800f7  SOUHHHH12AF729E4AF      2\n",
       "48373582  b7815dbb206eb2831ce0fe040d0aa537e2e800f7  SOUJVIT12A8C1451C1      1\n",
       "48373583  b7815dbb206eb2831ce0fe040d0aa537e2e800f7  SOUSMXX12AB0185C24      1\n",
       "48373584  b7815dbb206eb2831ce0fe040d0aa537e2e800f7  SOWYSKH12AF72A303A      3\n",
       "48373585  b7815dbb206eb2831ce0fe040d0aa537e2e800f7  SOYYFLV12A58A7A88F      1\n",
       "\n",
       "[48373586 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'data/train_triplets.txt'\n",
    "id_df = pd.read_csv(filename, delimiter='\\t',names=['user_id','song_id','count'])\n",
    "id_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in dataframe linking song_id to song titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-a6871d1b8ef7>:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  tracks_df = pd.read_csv(track_file,delimiter='<SEP>',names=['track_id','song_id','artist','song'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>song_id</th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRMMMYQ128F932D901</td>\n",
       "      <td>SOQMMHC12AB0180CB8</td>\n",
       "      <td>Faster Pussy cat</td>\n",
       "      <td>Silent Night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRMMMKD128F425225D</td>\n",
       "      <td>SOVFVAK12A8C1350D9</td>\n",
       "      <td>Karkkiautomaatti</td>\n",
       "      <td>Tanssi vaan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRMMMRX128F93187D9</td>\n",
       "      <td>SOGTUKN12AB017F4F1</td>\n",
       "      <td>Hudson Mohawke</td>\n",
       "      <td>No One Could Ever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRMMMCH128F425532C</td>\n",
       "      <td>SOBNYVR12A8C13558C</td>\n",
       "      <td>Yerba Brava</td>\n",
       "      <td>Si Vos Querés</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRMMMWA128F426B589</td>\n",
       "      <td>SOHSBXH12A8C13B0DF</td>\n",
       "      <td>Der Mystic</td>\n",
       "      <td>Tangle Of Aspens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>TRYYYUS12903CD2DF0</td>\n",
       "      <td>SOTXAME12AB018F136</td>\n",
       "      <td>Kiko Navarro</td>\n",
       "      <td>O Samba Da Vida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>TRYYYJO128F426DA37</td>\n",
       "      <td>SOXQYIQ12A8C137FBB</td>\n",
       "      <td>Kuldeep Manak</td>\n",
       "      <td>Jago Chhadeo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>TRYYYMG128F4260ECA</td>\n",
       "      <td>SOHODZI12A8C137BB3</td>\n",
       "      <td>Gabriel Le Mar</td>\n",
       "      <td>Novemba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>TRYYYDJ128F9310A21</td>\n",
       "      <td>SOLXGOR12A81C21EB7</td>\n",
       "      <td>Elude</td>\n",
       "      <td>Faraday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>TRYYYVU12903CD01E3</td>\n",
       "      <td>SOWXJXQ12AB0189F43</td>\n",
       "      <td>Texta</td>\n",
       "      <td>Fernweh feat. Sektion Kuchikäschtli</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  track_id             song_id            artist  \\\n",
       "0       TRMMMYQ128F932D901  SOQMMHC12AB0180CB8  Faster Pussy cat   \n",
       "1       TRMMMKD128F425225D  SOVFVAK12A8C1350D9  Karkkiautomaatti   \n",
       "2       TRMMMRX128F93187D9  SOGTUKN12AB017F4F1    Hudson Mohawke   \n",
       "3       TRMMMCH128F425532C  SOBNYVR12A8C13558C       Yerba Brava   \n",
       "4       TRMMMWA128F426B589  SOHSBXH12A8C13B0DF        Der Mystic   \n",
       "...                    ...                 ...               ...   \n",
       "999995  TRYYYUS12903CD2DF0  SOTXAME12AB018F136      Kiko Navarro   \n",
       "999996  TRYYYJO128F426DA37  SOXQYIQ12A8C137FBB     Kuldeep Manak   \n",
       "999997  TRYYYMG128F4260ECA  SOHODZI12A8C137BB3    Gabriel Le Mar   \n",
       "999998  TRYYYDJ128F9310A21  SOLXGOR12A81C21EB7             Elude   \n",
       "999999  TRYYYVU12903CD01E3  SOWXJXQ12AB0189F43             Texta   \n",
       "\n",
       "                                       song  \n",
       "0                              Silent Night  \n",
       "1                               Tanssi vaan  \n",
       "2                         No One Could Ever  \n",
       "3                             Si Vos Querés  \n",
       "4                          Tangle Of Aspens  \n",
       "...                                     ...  \n",
       "999995                      O Samba Da Vida  \n",
       "999996                         Jago Chhadeo  \n",
       "999997                              Novemba  \n",
       "999998                              Faraday  \n",
       "999999  Fernweh feat. Sektion Kuchikäschtli  \n",
       "\n",
       "[1000000 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_file = 'data/unique_tracks.txt'\n",
    "tracks_df = pd.read_csv(track_file,delimiter='<SEP>',names=['track_id','song_id','artist','song'])\n",
    "tracks_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now join those two dataframes on the shared song id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>song_id</th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>user_id</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRMMMYQ128F932D901</td>\n",
       "      <td>SOQMMHC12AB0180CB8</td>\n",
       "      <td>Faster Pussy cat</td>\n",
       "      <td>Silent Night</td>\n",
       "      <td>3a05343210b5e4b6308193bcd00242d326bd9b36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRMMMYQ128F932D901</td>\n",
       "      <td>SOQMMHC12AB0180CB8</td>\n",
       "      <td>Faster Pussy cat</td>\n",
       "      <td>Silent Night</td>\n",
       "      <td>93f24a7eb6742300414e7b8d4fefddf3f90c3db7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRMMMYQ128F932D901</td>\n",
       "      <td>SOQMMHC12AB0180CB8</td>\n",
       "      <td>Faster Pussy cat</td>\n",
       "      <td>Silent Night</td>\n",
       "      <td>53f8a04762e391eb0efb812b7352e4d598a48b2c</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRMMMCH128F425532C</td>\n",
       "      <td>SOBNYVR12A8C13558C</td>\n",
       "      <td>Yerba Brava</td>\n",
       "      <td>Si Vos Querés</td>\n",
       "      <td>baf8f44f7f23ca9671be11ff296df32a09f4406d</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRMMMCH128F425532C</td>\n",
       "      <td>SOBNYVR12A8C13558C</td>\n",
       "      <td>Yerba Brava</td>\n",
       "      <td>Si Vos Querés</td>\n",
       "      <td>c59ecc2ed2f13812c69a65c02d9847d255fa8ecf</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49664523</th>\n",
       "      <td>TRYYYZM128F428E804</td>\n",
       "      <td>SOBODSE12A8C13EBD6</td>\n",
       "      <td>SKYCLAD</td>\n",
       "      <td>Inequality Street</td>\n",
       "      <td>9ab8ef65e878846e1e2b4e1109ffa56b1a2c09bb</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49664524</th>\n",
       "      <td>TRYYYZM128F428E804</td>\n",
       "      <td>SOBODSE12A8C13EBD6</td>\n",
       "      <td>SKYCLAD</td>\n",
       "      <td>Inequality Street</td>\n",
       "      <td>56d29a12dbd87b619256e349d967fef6e1a46698</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49664525</th>\n",
       "      <td>TRYYYON128F932585A</td>\n",
       "      <td>SOWCNSN12AB018070F</td>\n",
       "      <td>Loose Shus</td>\n",
       "      <td>Taurus (Keenhouse Remix)</td>\n",
       "      <td>aeb227fce19da4e5a1d88f53df2ac0eb3ede4f74</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49664526</th>\n",
       "      <td>TRYYYON128F932585A</td>\n",
       "      <td>SOWCNSN12AB018070F</td>\n",
       "      <td>Loose Shus</td>\n",
       "      <td>Taurus (Keenhouse Remix)</td>\n",
       "      <td>95061cbe060d2500ce8af2bc71bcd9a6512352ba</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49664527</th>\n",
       "      <td>TRYYYVU12903CD01E3</td>\n",
       "      <td>SOWXJXQ12AB0189F43</td>\n",
       "      <td>Texta</td>\n",
       "      <td>Fernweh feat. Sektion Kuchikäschtli</td>\n",
       "      <td>73761dab0fa190edb18a2b21c4cfcf76d7cd8474</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49664528 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    track_id             song_id            artist  \\\n",
       "0         TRMMMYQ128F932D901  SOQMMHC12AB0180CB8  Faster Pussy cat   \n",
       "1         TRMMMYQ128F932D901  SOQMMHC12AB0180CB8  Faster Pussy cat   \n",
       "2         TRMMMYQ128F932D901  SOQMMHC12AB0180CB8  Faster Pussy cat   \n",
       "3         TRMMMCH128F425532C  SOBNYVR12A8C13558C       Yerba Brava   \n",
       "4         TRMMMCH128F425532C  SOBNYVR12A8C13558C       Yerba Brava   \n",
       "...                      ...                 ...               ...   \n",
       "49664523  TRYYYZM128F428E804  SOBODSE12A8C13EBD6           SKYCLAD   \n",
       "49664524  TRYYYZM128F428E804  SOBODSE12A8C13EBD6           SKYCLAD   \n",
       "49664525  TRYYYON128F932585A  SOWCNSN12AB018070F        Loose Shus   \n",
       "49664526  TRYYYON128F932585A  SOWCNSN12AB018070F        Loose Shus   \n",
       "49664527  TRYYYVU12903CD01E3  SOWXJXQ12AB0189F43             Texta   \n",
       "\n",
       "                                         song  \\\n",
       "0                                Silent Night   \n",
       "1                                Silent Night   \n",
       "2                                Silent Night   \n",
       "3                               Si Vos Querés   \n",
       "4                               Si Vos Querés   \n",
       "...                                       ...   \n",
       "49664523                    Inequality Street   \n",
       "49664524                    Inequality Street   \n",
       "49664525             Taurus (Keenhouse Remix)   \n",
       "49664526             Taurus (Keenhouse Remix)   \n",
       "49664527  Fernweh feat. Sektion Kuchikäschtli   \n",
       "\n",
       "                                           user_id  count  \n",
       "0         3a05343210b5e4b6308193bcd00242d326bd9b36      1  \n",
       "1         93f24a7eb6742300414e7b8d4fefddf3f90c3db7      6  \n",
       "2         53f8a04762e391eb0efb812b7352e4d598a48b2c      1  \n",
       "3         baf8f44f7f23ca9671be11ff296df32a09f4406d      1  \n",
       "4         c59ecc2ed2f13812c69a65c02d9847d255fa8ecf      1  \n",
       "...                                            ...    ...  \n",
       "49664523  9ab8ef65e878846e1e2b4e1109ffa56b1a2c09bb      1  \n",
       "49664524  56d29a12dbd87b619256e349d967fef6e1a46698      1  \n",
       "49664525  aeb227fce19da4e5a1d88f53df2ac0eb3ede4f74      1  \n",
       "49664526  95061cbe060d2500ce8af2bc71bcd9a6512352ba      2  \n",
       "49664527  73761dab0fa190edb18a2b21c4cfcf76d7cd8474      1  \n",
       "\n",
       "[49664528 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.merge(tracks_df, id_df, how='inner', on='song_id')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we read in our lyric data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found pickle file for current config, using that\n"
     ]
    }
   ],
   "source": [
    "sample_frac = 1.0\n",
    "\n",
    "pickle_filename = f\"data/lyrec_df_{sample_frac}.pkl\"\n",
    "print(\"Found pickle file for current config, using that\")\n",
    "giant_df = pd.read_pickle(pickle_filename)\n",
    "\n",
    "# giant_df = giant_df.sample(frac=1, random_state=1)\n",
    "lyric_df = giant_df.sample(frac=0.02,random_state = 1)\n",
    "#lyric_file = 'data/first1000.csv'\n",
    "\n",
    "#lyric_df = pd.read_csv(lyric_file)\n",
    "lyric_df['original_index'] = lyric_df.index\n",
    "# this is needed incase we want to map back to the original index in the lyric table after all the joins\n",
    "# lyric_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we join our data all together by matching on both artist and song name - this helps filter out duplicate song names, and there were many!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>song_id</th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>user_id</th>\n",
       "      <th>count</th>\n",
       "      <th>Band</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Song</th>\n",
       "      <th>original_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRMMMSA128F425FA38</td>\n",
       "      <td>SOBDLRM12A8C13A0AC</td>\n",
       "      <td>Lisa Brokop</td>\n",
       "      <td>Before He Kissed Me</td>\n",
       "      <td>0867f5b6eb9909754582f20890c8510c4d757e86</td>\n",
       "      <td>1</td>\n",
       "      <td>Lisa Brokop</td>\n",
       "      <td>He was a little too shy, a little too nice\\nI ...</td>\n",
       "      <td>Before He Kissed Me</td>\n",
       "      <td>469239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRMMMSA128F425FA38</td>\n",
       "      <td>SOBDLRM12A8C13A0AC</td>\n",
       "      <td>Lisa Brokop</td>\n",
       "      <td>Before He Kissed Me</td>\n",
       "      <td>1f12ba5107aa528a307d5e161abbea76a6da0e6b</td>\n",
       "      <td>1</td>\n",
       "      <td>Lisa Brokop</td>\n",
       "      <td>He was a little too shy, a little too nice\\nI ...</td>\n",
       "      <td>Before He Kissed Me</td>\n",
       "      <td>469239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRMMWNY12903CF28D2</td>\n",
       "      <td>SOVOIOQ12AC4688FAC</td>\n",
       "      <td>Warren Zevon</td>\n",
       "      <td>The Rest of the Night</td>\n",
       "      <td>5599c2947bb3a5a99f02aa44883ab437d123d3aa</td>\n",
       "      <td>1</td>\n",
       "      <td>Warren Zevon</td>\n",
       "      <td>Why stop now? let's party the rest of the nigh...</td>\n",
       "      <td>The Rest of the Night</td>\n",
       "      <td>114584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRMMWNY12903CF28D2</td>\n",
       "      <td>SOVOIOQ12AC4688FAC</td>\n",
       "      <td>Warren Zevon</td>\n",
       "      <td>The Rest of the Night</td>\n",
       "      <td>00a36bacc6f686cb2b4f334b6d7643e618d7ee3f</td>\n",
       "      <td>1</td>\n",
       "      <td>Warren Zevon</td>\n",
       "      <td>Why stop now? let's party the rest of the nigh...</td>\n",
       "      <td>The Rest of the Night</td>\n",
       "      <td>114584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRMMWNY12903CF28D2</td>\n",
       "      <td>SOVOIOQ12AC4688FAC</td>\n",
       "      <td>Warren Zevon</td>\n",
       "      <td>The Rest of the Night</td>\n",
       "      <td>6e76898d87867cf23d3e65ae17ab2457cc212ba1</td>\n",
       "      <td>1</td>\n",
       "      <td>Warren Zevon</td>\n",
       "      <td>Why stop now? let's party the rest of the nigh...</td>\n",
       "      <td>The Rest of the Night</td>\n",
       "      <td>114584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327560</th>\n",
       "      <td>TRYYTNW128F145C6E0</td>\n",
       "      <td>SOLAZNZ12AF729E299</td>\n",
       "      <td>Kajagoogoo</td>\n",
       "      <td>This Car Is Fast</td>\n",
       "      <td>f180196904f42738bc1526aee7e4d8d950fa8edd</td>\n",
       "      <td>1</td>\n",
       "      <td>Kajagoogoo</td>\n",
       "      <td>(VERSE 1)\\nNobody knew the people who were nee...</td>\n",
       "      <td>This Car Is Fast</td>\n",
       "      <td>369992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327561</th>\n",
       "      <td>TRYYTNW128F145C6E0</td>\n",
       "      <td>SOLAZNZ12AF729E299</td>\n",
       "      <td>Kajagoogoo</td>\n",
       "      <td>This Car Is Fast</td>\n",
       "      <td>688d80f6255305644e4d120c0cfba81683d5023b</td>\n",
       "      <td>1</td>\n",
       "      <td>Kajagoogoo</td>\n",
       "      <td>(VERSE 1)\\nNobody knew the people who were nee...</td>\n",
       "      <td>This Car Is Fast</td>\n",
       "      <td>369992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327562</th>\n",
       "      <td>TRYYSQN128F932EDCF</td>\n",
       "      <td>SOIIXQM12AB0187575</td>\n",
       "      <td>Boz Scaggs</td>\n",
       "      <td>Senza Fine</td>\n",
       "      <td>08538c6a0756775652f9cff4576fdadd211fdefb</td>\n",
       "      <td>17</td>\n",
       "      <td>Boz Scaggs</td>\n",
       "      <td>Senza fine\\nLet it always be senza fine\\nThere...</td>\n",
       "      <td>Senza Fine</td>\n",
       "      <td>67427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327563</th>\n",
       "      <td>TRYYSQN128F932EDCF</td>\n",
       "      <td>SOIIXQM12AB0187575</td>\n",
       "      <td>Boz Scaggs</td>\n",
       "      <td>Senza Fine</td>\n",
       "      <td>262477e1d5cfa374c04853f1803f08b81ccfbda4</td>\n",
       "      <td>1</td>\n",
       "      <td>Boz Scaggs</td>\n",
       "      <td>Senza fine\\nLet it always be senza fine\\nThere...</td>\n",
       "      <td>Senza Fine</td>\n",
       "      <td>67427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327564</th>\n",
       "      <td>TRYYSQN128F932EDCF</td>\n",
       "      <td>SOIIXQM12AB0187575</td>\n",
       "      <td>Boz Scaggs</td>\n",
       "      <td>Senza Fine</td>\n",
       "      <td>9982cdcb83ef260e3a2c7a65473c33973809ffbd</td>\n",
       "      <td>1</td>\n",
       "      <td>Boz Scaggs</td>\n",
       "      <td>Senza fine\\nLet it always be senza fine\\nThere...</td>\n",
       "      <td>Senza Fine</td>\n",
       "      <td>67427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>327565 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  track_id             song_id        artist  \\\n",
       "0       TRMMMSA128F425FA38  SOBDLRM12A8C13A0AC   Lisa Brokop   \n",
       "1       TRMMMSA128F425FA38  SOBDLRM12A8C13A0AC   Lisa Brokop   \n",
       "2       TRMMWNY12903CF28D2  SOVOIOQ12AC4688FAC  Warren Zevon   \n",
       "3       TRMMWNY12903CF28D2  SOVOIOQ12AC4688FAC  Warren Zevon   \n",
       "4       TRMMWNY12903CF28D2  SOVOIOQ12AC4688FAC  Warren Zevon   \n",
       "...                    ...                 ...           ...   \n",
       "327560  TRYYTNW128F145C6E0  SOLAZNZ12AF729E299    Kajagoogoo   \n",
       "327561  TRYYTNW128F145C6E0  SOLAZNZ12AF729E299    Kajagoogoo   \n",
       "327562  TRYYSQN128F932EDCF  SOIIXQM12AB0187575    Boz Scaggs   \n",
       "327563  TRYYSQN128F932EDCF  SOIIXQM12AB0187575    Boz Scaggs   \n",
       "327564  TRYYSQN128F932EDCF  SOIIXQM12AB0187575    Boz Scaggs   \n",
       "\n",
       "                         song                                   user_id  \\\n",
       "0         Before He Kissed Me  0867f5b6eb9909754582f20890c8510c4d757e86   \n",
       "1         Before He Kissed Me  1f12ba5107aa528a307d5e161abbea76a6da0e6b   \n",
       "2       The Rest of the Night  5599c2947bb3a5a99f02aa44883ab437d123d3aa   \n",
       "3       The Rest of the Night  00a36bacc6f686cb2b4f334b6d7643e618d7ee3f   \n",
       "4       The Rest of the Night  6e76898d87867cf23d3e65ae17ab2457cc212ba1   \n",
       "...                       ...                                       ...   \n",
       "327560       This Car Is Fast  f180196904f42738bc1526aee7e4d8d950fa8edd   \n",
       "327561       This Car Is Fast  688d80f6255305644e4d120c0cfba81683d5023b   \n",
       "327562             Senza Fine  08538c6a0756775652f9cff4576fdadd211fdefb   \n",
       "327563             Senza Fine  262477e1d5cfa374c04853f1803f08b81ccfbda4   \n",
       "327564             Senza Fine  9982cdcb83ef260e3a2c7a65473c33973809ffbd   \n",
       "\n",
       "        count          Band  \\\n",
       "0           1   Lisa Brokop   \n",
       "1           1   Lisa Brokop   \n",
       "2           1  Warren Zevon   \n",
       "3           1  Warren Zevon   \n",
       "4           1  Warren Zevon   \n",
       "...       ...           ...   \n",
       "327560      1    Kajagoogoo   \n",
       "327561      1    Kajagoogoo   \n",
       "327562     17    Boz Scaggs   \n",
       "327563      1    Boz Scaggs   \n",
       "327564      1    Boz Scaggs   \n",
       "\n",
       "                                                   Lyrics  \\\n",
       "0       He was a little too shy, a little too nice\\nI ...   \n",
       "1       He was a little too shy, a little too nice\\nI ...   \n",
       "2       Why stop now? let's party the rest of the nigh...   \n",
       "3       Why stop now? let's party the rest of the nigh...   \n",
       "4       Why stop now? let's party the rest of the nigh...   \n",
       "...                                                   ...   \n",
       "327560  (VERSE 1)\\nNobody knew the people who were nee...   \n",
       "327561  (VERSE 1)\\nNobody knew the people who were nee...   \n",
       "327562  Senza fine\\nLet it always be senza fine\\nThere...   \n",
       "327563  Senza fine\\nLet it always be senza fine\\nThere...   \n",
       "327564  Senza fine\\nLet it always be senza fine\\nThere...   \n",
       "\n",
       "                         Song  original_index  \n",
       "0         Before He Kissed Me          469239  \n",
       "1         Before He Kissed Me          469239  \n",
       "2       The Rest of the Night          114584  \n",
       "3       The Rest of the Night          114584  \n",
       "4       The Rest of the Night          114584  \n",
       "...                       ...             ...  \n",
       "327560       This Car Is Fast          369992  \n",
       "327561       This Car Is Fast          369992  \n",
       "327562             Senza Fine           67427  \n",
       "327563             Senza Fine           67427  \n",
       "327564             Senza Fine           67427  \n",
       "\n",
       "[327565 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.merge(df, lyric_df, how='inner',left_on=['song','artist'],right_on=['Song','Band'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique users:  225446\n",
      "unique songs:  904\n"
     ]
    }
   ],
   "source": [
    "# drop columns we won't need\n",
    "df.drop(columns=['track_id'])\n",
    "\n",
    "print(\"unique users: \", df['user_id'].unique().size)\n",
    "print(\"unique songs: \", df['song_id'].unique().size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step allows us to easily re-index our song id's into an easy to use form. We map song_id -> integer value that can be used to index our matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_SongID = df['song_id'].unique()\n",
    "unique_UserID = df['user_id'].unique()\n",
    "j = 0\n",
    "user_old2new_id_dict = dict()\n",
    "for u in unique_UserID:\n",
    "    user_old2new_id_dict[u] = j\n",
    "    j += 1\n",
    "j = 0\n",
    "song_old2new_id_dict = dict() \n",
    "for i in unique_SongID:\n",
    "    song_old2new_id_dict[i] = j\n",
    "    j += 1\n",
    "    \n",
    "# Then, use the generated dictionaries to reindex UserID and Song in the df\n",
    "for j in range(len(df)):\n",
    "    df.at[j, 'user_id'] = user_old2new_id_dict[df.at[j, 'user_id']]\n",
    "    df.at[j, 'song_id'] = song_old2new_id_dict[df.at[j, 'song_id']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>song_id</th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>user_id</th>\n",
       "      <th>count</th>\n",
       "      <th>Band</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Song</th>\n",
       "      <th>original_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRMMMSA128F425FA38</td>\n",
       "      <td>0</td>\n",
       "      <td>Lisa Brokop</td>\n",
       "      <td>Before He Kissed Me</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Lisa Brokop</td>\n",
       "      <td>He was a little too shy, a little too nice\\nI ...</td>\n",
       "      <td>Before He Kissed Me</td>\n",
       "      <td>469239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRMMMSA128F425FA38</td>\n",
       "      <td>0</td>\n",
       "      <td>Lisa Brokop</td>\n",
       "      <td>Before He Kissed Me</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Lisa Brokop</td>\n",
       "      <td>He was a little too shy, a little too nice\\nI ...</td>\n",
       "      <td>Before He Kissed Me</td>\n",
       "      <td>469239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRMMWNY12903CF28D2</td>\n",
       "      <td>1</td>\n",
       "      <td>Warren Zevon</td>\n",
       "      <td>The Rest of the Night</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Warren Zevon</td>\n",
       "      <td>Why stop now? let's party the rest of the nigh...</td>\n",
       "      <td>The Rest of the Night</td>\n",
       "      <td>114584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRMMWNY12903CF28D2</td>\n",
       "      <td>1</td>\n",
       "      <td>Warren Zevon</td>\n",
       "      <td>The Rest of the Night</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Warren Zevon</td>\n",
       "      <td>Why stop now? let's party the rest of the nigh...</td>\n",
       "      <td>The Rest of the Night</td>\n",
       "      <td>114584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRMMWNY12903CF28D2</td>\n",
       "      <td>1</td>\n",
       "      <td>Warren Zevon</td>\n",
       "      <td>The Rest of the Night</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Warren Zevon</td>\n",
       "      <td>Why stop now? let's party the rest of the nigh...</td>\n",
       "      <td>The Rest of the Night</td>\n",
       "      <td>114584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327560</th>\n",
       "      <td>TRYYTNW128F145C6E0</td>\n",
       "      <td>902</td>\n",
       "      <td>Kajagoogoo</td>\n",
       "      <td>This Car Is Fast</td>\n",
       "      <td>3179</td>\n",
       "      <td>1</td>\n",
       "      <td>Kajagoogoo</td>\n",
       "      <td>(VERSE 1)\\nNobody knew the people who were nee...</td>\n",
       "      <td>This Car Is Fast</td>\n",
       "      <td>369992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327561</th>\n",
       "      <td>TRYYTNW128F145C6E0</td>\n",
       "      <td>902</td>\n",
       "      <td>Kajagoogoo</td>\n",
       "      <td>This Car Is Fast</td>\n",
       "      <td>202196</td>\n",
       "      <td>1</td>\n",
       "      <td>Kajagoogoo</td>\n",
       "      <td>(VERSE 1)\\nNobody knew the people who were nee...</td>\n",
       "      <td>This Car Is Fast</td>\n",
       "      <td>369992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327562</th>\n",
       "      <td>TRYYSQN128F932EDCF</td>\n",
       "      <td>903</td>\n",
       "      <td>Boz Scaggs</td>\n",
       "      <td>Senza Fine</td>\n",
       "      <td>37242</td>\n",
       "      <td>17</td>\n",
       "      <td>Boz Scaggs</td>\n",
       "      <td>Senza fine\\nLet it always be senza fine\\nThere...</td>\n",
       "      <td>Senza Fine</td>\n",
       "      <td>67427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327563</th>\n",
       "      <td>TRYYSQN128F932EDCF</td>\n",
       "      <td>903</td>\n",
       "      <td>Boz Scaggs</td>\n",
       "      <td>Senza Fine</td>\n",
       "      <td>225444</td>\n",
       "      <td>1</td>\n",
       "      <td>Boz Scaggs</td>\n",
       "      <td>Senza fine\\nLet it always be senza fine\\nThere...</td>\n",
       "      <td>Senza Fine</td>\n",
       "      <td>67427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327564</th>\n",
       "      <td>TRYYSQN128F932EDCF</td>\n",
       "      <td>903</td>\n",
       "      <td>Boz Scaggs</td>\n",
       "      <td>Senza Fine</td>\n",
       "      <td>225445</td>\n",
       "      <td>1</td>\n",
       "      <td>Boz Scaggs</td>\n",
       "      <td>Senza fine\\nLet it always be senza fine\\nThere...</td>\n",
       "      <td>Senza Fine</td>\n",
       "      <td>67427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>327565 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  track_id song_id        artist                   song  \\\n",
       "0       TRMMMSA128F425FA38       0   Lisa Brokop    Before He Kissed Me   \n",
       "1       TRMMMSA128F425FA38       0   Lisa Brokop    Before He Kissed Me   \n",
       "2       TRMMWNY12903CF28D2       1  Warren Zevon  The Rest of the Night   \n",
       "3       TRMMWNY12903CF28D2       1  Warren Zevon  The Rest of the Night   \n",
       "4       TRMMWNY12903CF28D2       1  Warren Zevon  The Rest of the Night   \n",
       "...                    ...     ...           ...                    ...   \n",
       "327560  TRYYTNW128F145C6E0     902    Kajagoogoo       This Car Is Fast   \n",
       "327561  TRYYTNW128F145C6E0     902    Kajagoogoo       This Car Is Fast   \n",
       "327562  TRYYSQN128F932EDCF     903    Boz Scaggs             Senza Fine   \n",
       "327563  TRYYSQN128F932EDCF     903    Boz Scaggs             Senza Fine   \n",
       "327564  TRYYSQN128F932EDCF     903    Boz Scaggs             Senza Fine   \n",
       "\n",
       "       user_id  count          Band  \\\n",
       "0            0      1   Lisa Brokop   \n",
       "1            1      1   Lisa Brokop   \n",
       "2            2      1  Warren Zevon   \n",
       "3            3      1  Warren Zevon   \n",
       "4            4      1  Warren Zevon   \n",
       "...        ...    ...           ...   \n",
       "327560    3179      1    Kajagoogoo   \n",
       "327561  202196      1    Kajagoogoo   \n",
       "327562   37242     17    Boz Scaggs   \n",
       "327563  225444      1    Boz Scaggs   \n",
       "327564  225445      1    Boz Scaggs   \n",
       "\n",
       "                                                   Lyrics  \\\n",
       "0       He was a little too shy, a little too nice\\nI ...   \n",
       "1       He was a little too shy, a little too nice\\nI ...   \n",
       "2       Why stop now? let's party the rest of the nigh...   \n",
       "3       Why stop now? let's party the rest of the nigh...   \n",
       "4       Why stop now? let's party the rest of the nigh...   \n",
       "...                                                   ...   \n",
       "327560  (VERSE 1)\\nNobody knew the people who were nee...   \n",
       "327561  (VERSE 1)\\nNobody knew the people who were nee...   \n",
       "327562  Senza fine\\nLet it always be senza fine\\nThere...   \n",
       "327563  Senza fine\\nLet it always be senza fine\\nThere...   \n",
       "327564  Senza fine\\nLet it always be senza fine\\nThere...   \n",
       "\n",
       "                         Song  original_index  \n",
       "0         Before He Kissed Me          469239  \n",
       "1         Before He Kissed Me          469239  \n",
       "2       The Rest of the Night          114584  \n",
       "3       The Rest of the Night          114584  \n",
       "4       The Rest of the Night          114584  \n",
       "...                       ...             ...  \n",
       "327560       This Car Is Fast          369992  \n",
       "327561       This Car Is Fast          369992  \n",
       "327562             Senza Fine           67427  \n",
       "327563             Senza Fine           67427  \n",
       "327564             Senza Fine           67427  \n",
       "\n",
       "[327565 rows x 10 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Create Train & Test data\n",
    "\n",
    "Originally, we wanted the matrices we work with to be of dimension (users, songs), where each entry (u,s) is the number of times the user has listened to that song. However, we realized it is better to fill the matrices with the *fraction* of total listens for that particular user. This way, the model is agnostic of different users listening at differing rates.  \n",
    "\n",
    "First we sample our df to create our train and test data, and check for overlap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2292960\n",
      "982690\n",
      "no overlap!\n"
     ]
    }
   ],
   "source": [
    "train_df = df.sample(frac=0.7, random_state=0)\n",
    "test_df = df.drop(train_df.index)\n",
    "\n",
    "print(train_df.size)\n",
    "print(test_df.size)\n",
    "\n",
    "if(train_df.size + test_df.size == df.size):\n",
    "    print(\"no overlap!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(225446, 904)\n",
      "(225446, 904)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "num_user = len(df['user_id'].unique())\n",
    "num_song = len(df['song_id'].unique())\n",
    "\n",
    "train_mat = coo_matrix((train_df['count'].values, (train_df['user_id'].values, train_df['song_id'].values)), shape=(num_user, num_song)).toarray().astype(float)\n",
    "test_mat = coo_matrix((test_df['count'].values, (test_df['user_id'].values, test_df['song_id'].values)), shape=(num_user, num_song)).toarray().astype(float)\n",
    "\n",
    "# fill nan values\n",
    "train_mat[np.isnan(train_mat)] = 0\n",
    "test_mat[np.isnan(test_mat)] = 0\n",
    "\n",
    "print(train_mat.shape)\n",
    "print(test_mat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize the user counts, so every song listen value becomes a percentage of user listens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mat_counts = np.sum(train_mat,axis=1).T\n",
    "test_mat_counts = np.sum(test_mat,axis=1).T\n",
    "\n",
    "for user_id in range(num_user):\n",
    "    \n",
    "    denom = 1\n",
    "    if train_mat_counts[user_id] != 0:\n",
    "        denom = train_mat_counts[user_id]\n",
    "\n",
    "    train_mat[user_id] = train_mat[user_id]/denom\n",
    "    test_mat[user_id] = test_mat[user_id]/denom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Model Creation\n",
    "\n",
    "We will create and validate 3 models - Bag of Words, Bert, and a user-user MF model. All of these models will essentially generate latent features in some way given our (user, song) train data, and then generate predictions for fraction of listens. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3a: Bag of Words\n",
    "\n",
    "Our simple bag of words model has a few steps:\n",
    "\n",
    "1. For all lyrics, count the top N most frequent, nontrivial terms\n",
    "2. For each song, generate an N-length vector containing counts of those terms\n",
    "3. For each user, generate a user profile songs weighted by listens\n",
    "4. Produce a prediction for each user-song pair with the product of the user profile and song "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/george/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/george/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "import re\n",
    "from operator import itemgetter\n",
    "from sklearn.metrics import pairwise\n",
    "\n",
    "\n",
    "BAG_SIZE = 1000\n",
    "def get_top_values(d,N = BAG_SIZE):\n",
    "    return list(sorted(d.items(), key = itemgetter(1), reverse = True)[:N])\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "# creating  \"master\" dictionary\n",
    "word2count = {}\n",
    "\n",
    "for song_id in range(num_song):\n",
    "\n",
    "    # this will get the first index where song_id appears\n",
    "    lyric_idx = df[df['song_id']==song_id].index.values[0]\n",
    "    \n",
    "    # get song lyrics at that index\n",
    "    song_lyric = df.Lyrics.iloc[lyric_idx]\n",
    "\n",
    "    # clean song lyrics\n",
    "    song_lyric = song_lyric.lower()\n",
    "    song_lyric = re.sub(r'\\W', ' ', song_lyric)\n",
    "    song_lyic = re.sub(r'\\s+', ' ', song_lyric)\n",
    "    song_lyric = re.sub(r'\\r|\\n', ' ', song_lyric)\n",
    "\n",
    "    # get word counts for songs omitting stopwords\n",
    "    words = nltk.word_tokenize(song_lyric)\n",
    "    for word in words:\n",
    "\n",
    "        if word not in stop_words:\n",
    "\n",
    "            if word not in word2count:\n",
    "                word2count[word] = 1\n",
    "            else:\n",
    "                word2count[word] += 1\n",
    "\n",
    "# get the top ranked words for our songs\n",
    "\n",
    "word2count_list = get_top_values(word2count)\n",
    "word2count = dict(word2count_list)\n",
    "word_ranks = {w2c[0]: r for r, w2c in enumerate(word2count_list)}\n",
    "\n",
    "# Now pass through again and create vectors\n",
    "\n",
    "song_counts = np.zeros([num_song, BAG_SIZE])\n",
    "\n",
    "for song_id in range(num_song):\n",
    "\n",
    "    lyric_idx = df[df['song_id']==song_id].index.values[0]\n",
    "    \n",
    "    # get song lyrics at that index\n",
    "    song_lyric = df.Lyrics.iloc[lyric_idx]\n",
    "\n",
    "    # clean song lyrics\n",
    "    song_lyric = song_lyric.lower()\n",
    "    song_lyric = re.sub(r'\\W', ' ', song_lyric)\n",
    "    song_lyic = re.sub(r'\\s+', ' ', song_lyric)\n",
    "    song_lyric = re.sub(r'\\r|\\n', ' ', song_lyric)\n",
    "\n",
    "    words = nltk.word_tokenize(song_lyric)\n",
    "\n",
    "    for word in words:\n",
    "        if word in word_ranks:\n",
    "            word_idx = word_ranks[word]\n",
    "            song_counts[song_id][word_idx] += 1\n",
    "\n",
    "song_pairwise_similarities = pairwise.cosine_similarity(song_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Generate a user profile based on the tastes of each user. This will be a weighted average  \n",
    "of all the songs the user has listened to, based on relative number of listens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_user_profiles =  np.zeros([num_user, BAG_SIZE])\n",
    "bow_user_profiles = train_mat @ song_counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create predictions for bag of words by getting the product of user profiles with songs. Ignore users with no listens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-32-e59b10d7c89f>:11: RuntimeWarning: invalid value encountered in true_divide\n",
      "  bow_prediction_mat[user_id] = bow_prediction_mat[user_id]/denom\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.01382372, 0.001078  , 0.00202917, ..., 0.00076094, 0.00063412,\n",
       "        0.00234623],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.00039308, 0.03570107, 0.00187292, ..., 0.00055494, 0.00057806,\n",
       "        0.00217351],\n",
       "       ...,\n",
       "       [0.00039651, 0.00099128, 0.00043616, ..., 0.00174465, 0.10563045,\n",
       "        0.00051546],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.00162295, 0.00412317, 0.00377226, ..., 0.00074568, 0.00057023,\n",
       "        0.00995701]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_prediction_mat = bow_user_profiles @ song_counts.T\n",
    "\n",
    "bow_prediction_mat_counts = np.sum(bow_prediction_mat,axis=1).T\n",
    "\n",
    "for user_id in range(num_user):\n",
    "    \n",
    "#     denom = 1\n",
    "#     if bow_prediction_mat_counts[user_id] != 0:\n",
    "    denom = bow_prediction_mat_counts[user_id]\n",
    "\n",
    "    bow_prediction_mat[user_id] = bow_prediction_mat[user_id]/denom\n",
    "\n",
    "bow_prediction_mat[np.isnan(bow_prediction_mat)] = 0\n",
    "\n",
    "bow_prediction_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##3b: BERT\n",
    "\n",
    "Our BERT model is similarly structured, except how we get our latent features\n",
    "\n",
    "1. Compute latent features for lyrics by feeding into BERT, a pretrained model \n",
    "2. For each user, generate a user profile that is weighted by listens. So each user profile should be as long as the latent dimension\n",
    "3. Produce a prediction for each user-song pair with the product of the user profile and latent representation of the song\n",
    "\n",
    "First however, we have to read in our document embeddings that we computed earlier and wrote to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "sample_frac = 1.0\n",
    "filepath = f\"data/lyrec_embeddings_{sample_frac}.pkl.npy\"\n",
    "\n",
    "if os.path.isfile(filepath):\n",
    "    got_from_file = True\n",
    "    document_embeddings = np.load(filepath)\n",
    "else:\n",
    "    print('no file path')\n",
    "\n",
    "if not got_from_file:\n",
    "    np.save(filepath, document_embeddings)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(516174, 768)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use the original index to map back to the correct lyrics, since BERT computed many redundant lyric representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# subset_embeddings = document_embeddings[df.original_index]\n",
    "\n",
    "# print(document_embeddings.shape)\n",
    "# print(subset_embeddings.shape)\n",
    "# print(len(np.unique(subset_embeddings, axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(904, 768)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_bert = document_embeddings.shape[1]\n",
    "bert_factors = np.zeros([num_song, num_bert])\n",
    "\n",
    "for song_id in range(num_song):\n",
    "\n",
    "    # get the original index where the first song id appears in the df\n",
    "    idx = df[df['song_id']==song_id].index.values[0]\n",
    "\n",
    "    original_idx = df.original_index.iloc[idx]\n",
    "\n",
    "    # get song lyrics at that index\n",
    "    bert_factors[song_id] = document_embeddings[original_idx]\n",
    "\n",
    "bert_factors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute bert user profiles as the weighted average of latent representations of songs, weighted by the listens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(225446, 768)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_user_profiles =  np.zeros([num_user, num_bert])\n",
    "\n",
    "bert_user_profiles = train_mat @ bert_factors\n",
    "\n",
    "bert_user_profiles.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get product of user profiles and song representations for predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-39-8e92e46d0922>:9: RuntimeWarning: invalid value encountered in true_divide\n",
      "  bert_prediction_mat[user_id] = bert_prediction_mat[user_id]/denom\n"
     ]
    }
   ],
   "source": [
    "bert_prediction_mat = bert_user_profiles @ bert_factors.T\n",
    "bert_prediction_mat_counts = np.sum(bert_prediction_mat,axis=1).T\n",
    "\n",
    "for user_id in range(num_user):\n",
    "    \n",
    "    denom = bert_prediction_mat_counts[user_id]\n",
    "#     if bert_prediction_mat_counts[user_id] != 0:\n",
    "#         denom = bert_prediction_mat_counts[user_id]\n",
    "    bert_prediction_mat[user_id] = bert_prediction_mat[user_id]/denom\n",
    "\n",
    "bert_prediction_mat[np.isnan(bert_prediction_mat)] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: User-User MF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_rmse(test_mat,prediction_mat):\n",
    "    indicator_mat = (test_mat > 0).astype(float)\n",
    "    test_rmse = (np.sum(((prediction_mat - test_mat) * indicator_mat) ** 2) / np.sum(indicator_mat)) ** 0.5\n",
    "\n",
    "#     total = 0\n",
    "#     n = pred_mat.size\n",
    "# #     unrated = 0\n",
    "\n",
    "#     for user_id in range(num_user):\n",
    "\n",
    "# #         if np.sum(pred_mat[user_id])==0:\n",
    "# #             unrated += num_song\n",
    "# #         else:\n",
    "#         total += np.sum(np.square(test_mat[user_id] - pred_mat[user_id]))\n",
    "    \n",
    "    return test_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-100-3385d47f879b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterations\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mnmf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNMF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mW\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnmf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_mat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mfactorization_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnmf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mmf_mat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfactorization_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, W, H)\u001b[0m\n\u001b[0;32m   1281\u001b[0m                                 dtype=[np.float64, np.float32])\n\u001b[0;32m   1282\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1283\u001b[1;33m         W, H, n_iter_ = non_negative_factorization(\n\u001b[0m\u001b[0;32m   1284\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1285\u001b[0m             \u001b[0mupdate_H\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta_loss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbeta_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py\u001b[0m in \u001b[0;36mnon_negative_factorization\u001b[1;34m(X, W, H, n_components, init, update_H, solver, beta_loss, tol, max_iter, alpha, l1_ratio, regularization, random_state, verbose, shuffle)\u001b[0m\n\u001b[0;32m   1057\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1058\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msolver\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'cd'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1059\u001b[1;33m         W, H, n_iter = _fit_coordinate_descent(X, W, H, tol, max_iter,\n\u001b[0m\u001b[0;32m   1060\u001b[0m                                                \u001b[0ml1_reg_W\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml1_reg_H\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1061\u001b[0m                                                \u001b[0ml2_reg_W\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml2_reg_H\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py\u001b[0m in \u001b[0;36m_fit_coordinate_descent\u001b[1;34m(X, W, H, tol, max_iter, l1_reg_W, l1_reg_H, l2_reg_W, l2_reg_H, update_H, verbose, shuffle, random_state)\u001b[0m\n\u001b[0;32m    511\u001b[0m         \u001b[1;31m# Update H\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    512\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mupdate_H\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 513\u001b[1;33m             violation += _update_coordinate_descent(X.T, Ht, W, l1_reg_H,\n\u001b[0m\u001b[0;32m    514\u001b[0m                                                     l2_reg_H, shuffle, rng)\n\u001b[0;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py\u001b[0m in \u001b[0;36m_update_coordinate_descent\u001b[1;34m(X, W, Ht, l1_reg, l2_reg, shuffle, random_state)\u001b[0m\n\u001b[0;32m    405\u001b[0m     \u001b[0mn_components\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mHt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 407\u001b[1;33m     \u001b[0mHHt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mHt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    408\u001b[0m     \u001b[0mXHt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mHt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "iterations = [50,100,150,200,250,300]\n",
    "iter_rmse = []\n",
    "for i in iterations:\n",
    "    nmf = NMF(max_iter=i)\n",
    "    W = nmf.fit_transform(train_mat)\n",
    "    factorization_matrix = nmf.components_\n",
    "    mf_mat = np.dot(W,factorization_matrix)\n",
    "\n",
    "    iter_rmse.append(new_rmse(test_mat,mf_mat))\n",
    "\n",
    "plt.plot(iterations, iter_rmse)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bag of words rmse:  5.292967905447446\n",
      "BERT rmse:  5.293784769054346\n",
      "baseline rmse:  5.117294288972029\n"
     ]
    }
   ],
   "source": [
    "print('bag of words rmse: ', new_rmse(test_mat,bow_prediction_mat))\n",
    "print('BERT rmse: ', new_rmse(test_mat,bert_prediction_mat))\n",
    "print('baseline rmse: ', new_rmse(test_mat,np.random.rand(num_user,num_song)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE between test and train:  5.285893020175084\n"
     ]
    }
   ],
   "source": [
    "print('RMSE between test and train: ', new_rmse(test_mat,train_mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [0.1 * i for i in range(10)]\n",
    "alpha_rmse = []\n",
    "for i in a:\n",
    "    nmf = NMF(alpha=i)\n",
    "    W = nmf.fit_transform(train_mat)\n",
    "    factorization_matrix = nmf.components_\n",
    "    mf_mat = np.dot(W,factorization_matrix)\n",
    "\n",
    "    alpha_rmse.append(new_rmse(test_mat,mf_mat))\n",
    "\n",
    "plt.plot(a, alpha_rmse)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_ratio = [0.1 * i for i in range(10)]\n",
    "l1_rmse = []\n",
    "for i in a:\n",
    "    nmf = NMF(l1_ratio=i)\n",
    "    W = nmf.fit_transform(train_mat)\n",
    "    factorization_matrix = nmf.components_\n",
    "    mf_mat = np.dot(W,factorization_matrix)\n",
    "\n",
    "    l1_rmse.append(new_rmse(test_mat,mf_mat))\n",
    "\n",
    "plt.plot(l1_ratio, l1_rmse)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-dc7520a7c18b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# optimal model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnmf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNMF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnmf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mfactorization_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnmf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmf_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfactorization_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, W, H)\u001b[0m\n\u001b[1;32m   1281\u001b[0m                                 dtype=[np.float64, np.float32])\n\u001b[1;32m   1282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1283\u001b[0;31m         W, H, n_iter_ = non_negative_factorization(\n\u001b[0m\u001b[1;32m   1284\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m             \u001b[0mupdate_H\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py\u001b[0m in \u001b[0;36mnon_negative_factorization\u001b[0;34m(X, W, H, n_components, init, update_H, solver, beta_loss, tol, max_iter, alpha, l1_ratio, regularization, random_state, verbose, shuffle)\u001b[0m\n\u001b[1;32m   1057\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'cd'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m         W, H, n_iter = _fit_coordinate_descent(X, W, H, tol, max_iter,\n\u001b[0m\u001b[1;32m   1060\u001b[0m                                                \u001b[0ml1_reg_W\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml1_reg_H\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m                                                \u001b[0ml2_reg_W\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2_reg_H\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py\u001b[0m in \u001b[0;36m_fit_coordinate_descent\u001b[0;34m(X, W, H, tol, max_iter, l1_reg_W, l1_reg_H, l2_reg_W, l2_reg_H, update_H, verbose, shuffle, random_state)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0;31m# Update W\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m         violation += _update_coordinate_descent(X, W, Ht, l1_reg_W,\n\u001b[0m\u001b[1;32m    510\u001b[0m                                                 l2_reg_W, shuffle, rng)\n\u001b[1;32m    511\u001b[0m         \u001b[0;31m# Update H\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py\u001b[0m in \u001b[0;36m_update_coordinate_descent\u001b[0;34m(X, W, Ht, l1_reg, l2_reg, shuffle, random_state)\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;31m# The following seems to be required on 64-bit Windows w/ Python 3.5.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0mpermutation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_update_cdnmf_fast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHHt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXHt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpermutation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# optimal model\n",
    "nmf = NMF(verbose=1)\n",
    "W = nmf.fit_transform(train_mat)\n",
    "factorization_matrix = nmf.components_\n",
    "mf_mat = np.dot(W,factorization_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a new rmse function that ignores users with zero listens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('baseline rmse: ', new_rmse(test_mat,np.random.rand(num_user,num_song)))\n",
    "print('user-user rmse: ', new_rmse(test_mat,mf_mat))\n",
    "print('bag of words rmse: ', new_rmse(test_mat,bow_prediction_mat))\n",
    "print('BERT rmse: ', new_rmse(test_mat,bert_prediction_mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
