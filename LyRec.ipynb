{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm().pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num rows 516174\n"
     ]
    }
   ],
   "source": [
    "from ftfy import fix_text\n",
    "import threading\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import os\n",
    "\n",
    "filename = 'data/fulldataset.csv'\n",
    "sample_frac = 1.0\n",
    "\n",
    "df = pd.read_csv(filename,quotechar=\"\\\"\")\n",
    "df = df.sample(frac=sample_frac, random_state=1)\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "num_rows = len(df.index)\n",
    "print(\"num rows\", num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Band</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Song</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mariah Carry</td>\n",
       "      <td>I don't want a lot for Christmas\\nThere is jus...</td>\n",
       "      <td>All I Want for Christmas is You</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wham!</td>\n",
       "      <td>Last Christmas I gave you my heart\\nBut the ve...</td>\n",
       "      <td>Last Christmas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Idk</td>\n",
       "      <td>Jingle bells, jingle bells, jingle all the way...</td>\n",
       "      <td>Jingle Bells</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Johnny Mathis</td>\n",
       "      <td>Jingle bell, jingle bell Jingle bell rock Jing...</td>\n",
       "      <td>Jingle Bell Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lee Greenwood</td>\n",
       "      <td>If tomorrow all the things were gone\\nI worked...</td>\n",
       "      <td>God Bless the USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Samuel Ward</td>\n",
       "      <td>Oh beautiful for heroes proved\\nIn liberating ...</td>\n",
       "      <td>America the Beautiful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Francis Scott Key</td>\n",
       "      <td>Oh, say can you see by the dawn’s early light\\...</td>\n",
       "      <td>Star Spangled Banner</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Band                                             Lyrics  \\\n",
       "0       Mariah Carry  I don't want a lot for Christmas\\nThere is jus...   \n",
       "1              Wham!  Last Christmas I gave you my heart\\nBut the ve...   \n",
       "2                Idk  Jingle bells, jingle bells, jingle all the way...   \n",
       "3      Johnny Mathis  Jingle bell, jingle bell Jingle bell rock Jing...   \n",
       "4      Lee Greenwood  If tomorrow all the things were gone\\nI worked...   \n",
       "5        Samuel Ward  Oh beautiful for heroes proved\\nIn liberating ...   \n",
       "6  Francis Scott Key  Oh, say can you see by the dawn’s early light\\...   \n",
       "\n",
       "                              Song  \n",
       "0  All I Want for Christmas is You  \n",
       "1                   Last Christmas  \n",
       "2                     Jingle Bells  \n",
       "3                 Jingle Bell Rock  \n",
       "4                God Bless the USA  \n",
       "5            America the Beautiful  \n",
       "6             Star Spangled Banner  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check cell, skip this cell (and the next one) if training on full data\n",
    "df = pd.read_csv('sanity_check.csv')\n",
    "sample_frac = 1.0\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning dataset, no cache available\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "807e087f1a244b52800683a0ba973772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=516174.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error cleaning up row: 18082 dropping instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error cleaning up row: 457340 dropping instead\n",
      "Error cleaning up row: 515163 dropping instead\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Band</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Song</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reba McEntire</td>\n",
       "      <td>The greatest man I never knew lived just down ...</td>\n",
       "      <td>The Greatest Man I Never Knew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vanessa Carlton</td>\n",
       "      <td>Stealing glances through the key hole\\nIn a br...</td>\n",
       "      <td>Hear the Bells</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Snoop Dogg</td>\n",
       "      <td>What it do,\\nComing at you live, it's your boy...</td>\n",
       "      <td>Pronto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Snoop Dogg</td>\n",
       "      <td>Another smoke session up in this motherfucker\\...</td>\n",
       "      <td>Buss 'N Rocks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Shirelles</td>\n",
       "      <td>Everybody, twist\\n\\nThey're twisting in Clevel...</td>\n",
       "      <td>Twisting USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516169</th>\n",
       "      <td>Erika Paul</td>\n",
       "      <td>Sassy Sarah On The Saxophone\\n\\nWords &amp; Music ...</td>\n",
       "      <td>Sassy Sarah on the Saxophone [Funk Fusion]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516170</th>\n",
       "      <td>Billy Currington</td>\n",
       "      <td>This porch light\\nI can keep it on all night\\n...</td>\n",
       "      <td>Jonesin'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516171</th>\n",
       "      <td>Barbra Streisand</td>\n",
       "      <td>I'm dreaming tonight\\nOf a place I love\\nEven ...</td>\n",
       "      <td>I'll Be Home for Christmas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516172</th>\n",
       "      <td>Daniel Johnston</td>\n",
       "      <td>Without you, I'll be doing fine\\nWithout you, ...</td>\n",
       "      <td>Without You</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516173</th>\n",
       "      <td>Jerry Vale</td>\n",
       "      <td>Oh luna rossa, you're out tonight,\\nA moon of ...</td>\n",
       "      <td>Luna Rossa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>516174 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Band                                             Lyrics  \\\n",
       "0          Reba McEntire  The greatest man I never knew lived just down ...   \n",
       "1        Vanessa Carlton  Stealing glances through the key hole\\nIn a br...   \n",
       "2             Snoop Dogg  What it do,\\nComing at you live, it's your boy...   \n",
       "3             Snoop Dogg  Another smoke session up in this motherfucker\\...   \n",
       "4          The Shirelles  Everybody, twist\\n\\nThey're twisting in Clevel...   \n",
       "...                  ...                                                ...   \n",
       "516169        Erika Paul  Sassy Sarah On The Saxophone\\n\\nWords & Music ...   \n",
       "516170  Billy Currington  This porch light\\nI can keep it on all night\\n...   \n",
       "516171  Barbra Streisand  I'm dreaming tonight\\nOf a place I love\\nEven ...   \n",
       "516172   Daniel Johnston  Without you, I'll be doing fine\\nWithout you, ...   \n",
       "516173        Jerry Vale  Oh luna rossa, you're out tonight,\\nA moon of ...   \n",
       "\n",
       "                                              Song  \n",
       "0                    The Greatest Man I Never Knew  \n",
       "1                                   Hear the Bells  \n",
       "2                                           Pronto  \n",
       "3                                    Buss 'N Rocks  \n",
       "4                                     Twisting USA  \n",
       "...                                            ...  \n",
       "516169  Sassy Sarah on the Saxophone [Funk Fusion]  \n",
       "516170                                    Jonesin'  \n",
       "516171                  I'll Be Home for Christmas  \n",
       "516172                                 Without You  \n",
       "516173                                  Luna Rossa  \n",
       "\n",
       "[516174 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle_filename = f\"data/lyrec_df_{sample_frac}.pkl\"\n",
    "if os.path.isfile(pickle_filename):\n",
    "    print(\"Found pickle file for current config, using that\")\n",
    "    df = pd.read_pickle(pickle_filename)\n",
    "else:\n",
    "    print(\"Cleaning dataset, no cache available\")\n",
    "    pbar = tqdm(total=(num_rows))\n",
    "    def clean(row):\n",
    "        try:\n",
    "            lyric = fix_text(df['Lyrics'][row])\n",
    "            band = fix_text(df['Band'][row])\n",
    "            song = fix_text(df['Song'][row])\n",
    "            df['Lyrics'][row] = lyric\n",
    "            df['Band'][row] = band\n",
    "            df['Song'][row] = song\n",
    "        except Exception:\n",
    "            print(\"Error cleaning up row:\", row,\"dropping instead\")\n",
    "            df.drop(index=row)\n",
    "        pbar.update(1)\n",
    "\n",
    "    executor = ThreadPoolExecutor(10)\n",
    "    threads = []\n",
    "    for row in df.index:\n",
    "        t = executor.submit(clean, (row))\n",
    "        threads.append(t)\n",
    "\n",
    "    for t in threads:\n",
    "        t.result()\n",
    "\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataset to pickle\n",
    "df.to_pickle(pickle_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt at BERT pairwise similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a803de0dd425476d8805129a57fc0378",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Batches'), FloatProgress(value=0.0, max=16131.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "sbert_model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "document_embeddings = None\n",
    "got_from_file = False\n",
    "filepath = f\"data/lyrec_embeddings_{sample_frac}.pkl\"\n",
    "\n",
    "if os.path.isfile(filepath):\n",
    "    got_from_file = True\n",
    "    with open(filepath, 'rb') as f:\n",
    "        document_embeddings = np.load(f)\n",
    "else:\n",
    "    document_embeddings = sbert_model.encode(df['Lyrics'], show_progress_bar=True, device=\"cpu\")\n",
    "\n",
    "if not got_from_file:\n",
    "    with open(filepath, 'wb') as f:\n",
    "        np.save(document_embeddings, filepath)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'document_embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f570e2e63725>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpairwise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpairwise_similarities\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpairwise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpairwise_differences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpairwise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meuclidean_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'document_embeddings' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import pairwise\n",
    "print(document_embeddings.shape)\n",
    "pairwise_similarities=pairwise.cosine_similarity(document_embeddings)\n",
    "pairwise_differences=pairwise.euclidean_distances(document_embeddings)\n",
    "\n",
    "def most_similar(doc_id,similarity_matrix,matrix):\n",
    "    print (f'Song: {df.iloc[doc_id][\"Song\"]} - {df.iloc[doc_id][\"Band\"]}')\n",
    "    print ('\\n')\n",
    "    print ('Similar Songs:')\n",
    "    if matrix=='Cosine Similarity':\n",
    "        similar_ix=np.argsort(similarity_matrix[doc_id])[::-1]\n",
    "    elif matrix=='Euclidean Distance':\n",
    "        similar_ix=np.argsort(similarity_matrix[doc_id])\n",
    "    for ix in similar_ix[:5]:\n",
    "#         if ix==doc_id:\n",
    "#             continue\n",
    "        print('\\n')\n",
    "        print (f'Similar Song: {df.iloc[ix][\"Song\"]} - {df.iloc[ix][\"Band\"]}')\n",
    "        print (f'{matrix} : {similarity_matrix[doc_id][ix]}')\n",
    "\n",
    "for i in range(7):\n",
    "    most_similar(i,pairwise_similarities,'Cosine Similarity')\n",
    "    print(\"---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'jingle': 49, 'christmas': 23, 'oh': 21, 'bells': 20, 'gave': 20, 'bell': 19, 'want': 16, 'one': 15, 'baby': 14, 'horse': 14, 'sleigh': 13, 'special': 13, 'away': 12, 'know': 11, 'fun': 11, 'next': 10, 'time': 10, 'heart': 9, 'someone': 9, 'god': 9, 'way': 9, 'ride': 9, 'open': 9, 'year': 8, 'give': 8, 'land': 8, 'america': 8, 'day': 7, 'cause': 7, 'last': 7, 'save': 7, 'love': 7, 'rock': 7, 'free': 7, 'sea': 7, 'right': 6, 'tears': 6, 'still': 6, 'er': 6, 'home': 6, 'make': 5, 'wish': 5, 'shining': 5, 'bright': 5, 'stand': 5, 'need': 4, 'could': 4, 'ever': 4, 'go': 4, 'ring': 4, 'sing': 4, 'today': 4, 'american': 4, 'star': 4, 'spangled': 4, 'banner': 4, 'wave': 4, 'brave': 4, 'lot': 3, 'underneath': 3, 'come': 3, 'true': 3, 'snow': 3, 'tonight': 3, 'air': 3, 'see': 3, 'fool': 3, 'night': 3, 'proud': 3, 'least': 3, 'forget': 3, 'men': 3, 'died': 3, 'gladly': 3, 'defend': 3, 'doubt': 3, 'bless': 3, 'u': 3, 'say': 3, 'may': 3, 'thy': 3, 'shed': 3, 'grace': 3, 'thee': 3, 'lord': 3, 'thing': 2, 'care': 2, 'presents': 2, 'tree': 2, 'santa': 2, 'even': 2, 'na': 2, 'keep': 2, 'hear': 2, 'children': 2, 'bring': 2, 'face': 2, 'lover': 2, 'fire': 2, 'man': 2}\n",
      "[[ 0. 16.  4.  1.  0.  0. 16.  3. 12.  0.  1.  0.  0.  3.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  1.\n",
      "   0.  0.  0.  0.  5.  4.  1.  0.  0.  4.  3.  3.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  3.  3.  3.  3.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  2.  2.  2.  2.\n",
      "   2.  2.  1.  2.  1.  2.  0.  0.  0.  0.]\n",
      " [ 0.  7.  2.  0. 16.  0.  0.  0.  2.  0.  0. 13.  9.  2.  0.  7.  0.  8.\n",
      "   9.  1.  0.  0.  0.  8.  8.  0.  0.  6.  0.  6.  6.  2.  0.  0.  0.  0.\n",
      "   6.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  3.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  1.  0.  0.  0.  2.  2.  2.  2.]\n",
      " [21.  0.  7. 16.  0.  0.  0.  9.  0.  9.  9.  0.  0.  0.  9.  0.  0.  0.\n",
      "   0.  0.  9.  9.  9.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  2.  0.  0.  0.  0.  2.  2.  2.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  2.  2.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [28.  0.  0.  3.  0. 19.  0.  3.  0.  5.  3.  0.  2.  0.  2.  0.  9.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  7.  0.  0.  2.\n",
      "   0.  0.  0.  0.  0.  0.  0.  2.  0.  0.  0.  0.  2.  2.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  2.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  3.  0.  0.  0.  0.  0.  0.  0.  1.  3.  0.  3.  1.  1.\n",
      "   0.  3.  0.  0.  0.  0.  0.  3.  0.  0.  4.  0.  0.  3.  0.  3.  2.  3.\n",
      "   0.  4.  0.  0.  0.  0.  1.  0.  4.  0.  0.  0.  0.  0.  0.  4.  4.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  3.  3.  3.  3.\n",
      "   3.  3.  3.  3.  3.  3.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  4.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  3.  0.  0.  0.  0.\n",
      "   0.  4.  0.  0.  0.  0.  0.  0.  8.  0.  1.  0.  0.  2.  0.  0.  5.  0.\n",
      "   0.  0.  0.  0.  0.  1.  3.  0.  0.  0.  0.  0.  0.  0.  2.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  1.  3.  3.  3.  3.  3.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  4.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  1.  0.  0.  0.  0.  0.  5.  0.  0.  1.  1.  1.  0.  0.  4.  0.  0.\n",
      "   0.  1.  6.  6.  0.  0.  0.  1.  1.  0.  1.  1.  0.  0.  0.  0.  0.  4.\n",
      "   4.  4.  4.  4.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  2.  2.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "Song: All I Want for Christmas is You - Mariah Carry\n",
      "Similar Songs:\n",
      "\n",
      "\n",
      "Similar Song: All I Want for Christmas is You - Mariah Carry\n",
      "Cosine Similarity : 1.0\n",
      "\n",
      "\n",
      "Similar Song: Last Christmas - Wham!\n",
      "Cosine Similarity : 0.16510909745494848\n",
      "\n",
      "\n",
      "Similar Song: America the Beautiful -  Samuel Ward\n",
      "Cosine Similarity : 0.0833483556566276\n",
      "\n",
      "\n",
      "Similar Song: Jingle Bells - Idk\n",
      "Cosine Similarity : 0.07884238209468103\n",
      "\n",
      "\n",
      "Similar Song: Star Spangled Banner - Francis Scott Key\n",
      "Cosine Similarity : 0.05657469815696952\n",
      "---\n",
      "Song: Last Christmas - Wham!\n",
      "Similar Songs:\n",
      "\n",
      "\n",
      "Similar Song: Last Christmas - Wham!\n",
      "Cosine Similarity : 1.0\n",
      "\n",
      "\n",
      "Similar Song: God Bless the USA - Lee Greenwood\n",
      "Cosine Similarity : 0.2026815536909384\n",
      "\n",
      "\n",
      "Similar Song: All I Want for Christmas is You - Mariah Carry\n",
      "Cosine Similarity : 0.16510909745494848\n",
      "\n",
      "\n",
      "Similar Song: Star Spangled Banner - Francis Scott Key\n",
      "Cosine Similarity : 0.0767794284212883\n",
      "\n",
      "\n",
      "Similar Song: America the Beautiful -  Samuel Ward\n",
      "Cosine Similarity : 0.048152611024248934\n",
      "---\n",
      "Song: Jingle Bells - Idk\n",
      "Similar Songs:\n",
      "\n",
      "\n",
      "Similar Song: Jingle Bells - Idk\n",
      "Cosine Similarity : 0.9999999999999998\n",
      "\n",
      "\n",
      "Similar Song: Jingle Bell Rock - Johnny Mathis\n",
      "Cosine Similarity : 0.5681537620992175\n",
      "\n",
      "\n",
      "Similar Song: All I Want for Christmas is You - Mariah Carry\n",
      "Cosine Similarity : 0.07884238209468103\n",
      "\n",
      "\n",
      "Similar Song: America the Beautiful -  Samuel Ward\n",
      "Cosine Similarity : 0.06251097014221936\n",
      "\n",
      "\n",
      "Similar Song: Star Spangled Banner - Francis Scott Key\n",
      "Cosine Similarity : 0.05409929842380854\n",
      "---\n",
      "Song: Jingle Bell Rock - Johnny Mathis\n",
      "Similar Songs:\n",
      "\n",
      "\n",
      "Similar Song: Jingle Bell Rock - Johnny Mathis\n",
      "Cosine Similarity : 1.0000000000000002\n",
      "\n",
      "\n",
      "Similar Song: Jingle Bells - Idk\n",
      "Cosine Similarity : 0.5681537620992175\n",
      "\n",
      "\n",
      "Similar Song: God Bless the USA - Lee Greenwood\n",
      "Cosine Similarity : 0.029081634119948897\n",
      "\n",
      "\n",
      "Similar Song: All I Want for Christmas is You - Mariah Carry\n",
      "Cosine Similarity : 0.016776015364689784\n",
      "\n",
      "\n",
      "Similar Song: Last Christmas - Wham!\n",
      "Cosine Similarity : 0.01497848388302791\n",
      "---\n",
      "Song: God Bless the USA - Lee Greenwood\n",
      "Similar Songs:\n",
      "\n",
      "\n",
      "Similar Song: God Bless the USA - Lee Greenwood\n",
      "Cosine Similarity : 0.9999999999999997\n",
      "\n",
      "\n",
      "Similar Song: Last Christmas - Wham!\n",
      "Cosine Similarity : 0.2026815536909384\n",
      "\n",
      "\n",
      "Similar Song: America the Beautiful -  Samuel Ward\n",
      "Cosine Similarity : 0.19798139062388093\n",
      "\n",
      "\n",
      "Similar Song: Star Spangled Banner - Francis Scott Key\n",
      "Cosine Similarity : 0.19522420795936382\n",
      "\n",
      "\n",
      "Similar Song: All I Want for Christmas is You - Mariah Carry\n",
      "Cosine Similarity : 0.03891512139769416\n",
      "---\n",
      "Song: America the Beautiful -  Samuel Ward\n",
      "Similar Songs:\n",
      "\n",
      "\n",
      "Similar Song: America the Beautiful -  Samuel Ward\n",
      "Cosine Similarity : 0.9999999999999997\n",
      "\n",
      "\n",
      "Similar Song: God Bless the USA - Lee Greenwood\n",
      "Cosine Similarity : 0.19798139062388093\n",
      "\n",
      "\n",
      "Similar Song: Star Spangled Banner - Francis Scott Key\n",
      "Cosine Similarity : 0.11303665258213491\n",
      "\n",
      "\n",
      "Similar Song: All I Want for Christmas is You - Mariah Carry\n",
      "Cosine Similarity : 0.0833483556566276\n",
      "\n",
      "\n",
      "Similar Song: Jingle Bells - Idk\n",
      "Cosine Similarity : 0.06251097014221936\n",
      "---\n",
      "Song: Star Spangled Banner - Francis Scott Key\n",
      "Similar Songs:\n",
      "\n",
      "\n",
      "Similar Song: Star Spangled Banner - Francis Scott Key\n",
      "Cosine Similarity : 0.9999999999999999\n",
      "\n",
      "\n",
      "Similar Song: God Bless the USA - Lee Greenwood\n",
      "Cosine Similarity : 0.19522420795936382\n",
      "\n",
      "\n",
      "Similar Song: America the Beautiful -  Samuel Ward\n",
      "Cosine Similarity : 0.11303665258213491\n",
      "\n",
      "\n",
      "Similar Song: Last Christmas - Wham!\n",
      "Cosine Similarity : 0.0767794284212883\n",
      "\n",
      "\n",
      "Similar Song: All I Want for Christmas is You - Mariah Carry\n",
      "Cosine Similarity : 0.05657469815696952\n",
      "---\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Aditya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Aditya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "import re\n",
    "from operator import itemgetter\n",
    "from sklearn.metrics import pairwise\n",
    "# Define dictionary utility function\n",
    "BAG_SIZE = 100\n",
    "def get_top_values(d,N = BAG_SIZE):\n",
    "    return list(sorted(d.items(), key = itemgetter(1), reverse = True)[:N])\n",
    "\n",
    "# Preprocess songs\n",
    "\n",
    "# set stop words in english\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "# creating  \"master\" dictionary\n",
    "word2count = {}\n",
    "\n",
    "for row in df.index:\n",
    "    song = df['Lyrics'][row]\n",
    "\n",
    "    # remove stopwords and clean up each song\n",
    "    song = song.lower()\n",
    "    song = re.sub(r'\\W', ' ', song)\n",
    "    song = re.sub(r'\\s+', ' ', song)\n",
    "    song = re.sub(r'\\r|\\n', ' ', song)\n",
    "\n",
    "    words = nltk.word_tokenize(song)\n",
    "    for word in words:\n",
    "\n",
    "        if word not in stop_words:\n",
    "\n",
    "            if word not in word2count.keys():\n",
    "                word2count[word] = 1\n",
    "            else:\n",
    "                word2count[word] += 1\n",
    "\n",
    "word2count_list = get_top_values(word2count)\n",
    "word2count = dict(word2count_list)\n",
    "word_ranks = {w2c[0]: r for r, w2c in enumerate(word2count_list)}\n",
    "\n",
    "# Now pass through again and create vectors\n",
    "\n",
    "song_counts = np.zeros([len(df.index), BAG_SIZE])\n",
    "\n",
    "for song_index in df.index:\n",
    "\n",
    "    song = df['Lyrics'][song_index]\n",
    "\n",
    "    # remove stopwords and clean up each song\n",
    "    song = song.lower()\n",
    "    song = re.sub(r'\\W', ' ', song)\n",
    "    song = re.sub(r'\\s+', ' ', song)\n",
    "    song = re.sub(r'\\r|\\n', ' ', song)\n",
    "\n",
    "    words = nltk.word_tokenize(song)\n",
    "    for word in words:\n",
    "        if word in word_ranks:\n",
    "            word_idx = word_ranks[word]\n",
    "            song_counts[song_index][word_idx] += 1\n",
    "\n",
    "print(word2count)\n",
    "print(song_counts)\n",
    "\n",
    "\n",
    "pairwise_similarities=pairwise.cosine_similarity(song_counts)\n",
    "pairwise_differences=pairwise.euclidean_distances(song_counts)\n",
    "\n",
    "\n",
    "def most_similar(doc_id,similarity_matrix,matrix):\n",
    "    print (f'Song: {df.iloc[doc_id][\"Song\"]} - {df.iloc[doc_id][\"Band\"]}')\n",
    "    print ('Similar Songs:')\n",
    "    \n",
    "    if matrix=='Cosine Similarity':\n",
    "        similar_ix=np.argsort(similarity_matrix[doc_id])[::-1]\n",
    "    elif matrix=='Euclidean Distance':\n",
    "        similar_ix=np.argsort(similarity_matrix[doc_id])\n",
    "    for ix in similar_ix[:5]:\n",
    "#         if ix==doc_id:\n",
    "#             continue\n",
    "        print('\\n')\n",
    "        print (f'Similar Song: {df.iloc[ix][\"Song\"]} - {df.iloc[ix][\"Band\"]}')\n",
    "        print (f'{matrix} : {similarity_matrix[doc_id][ix]}')\n",
    "\n",
    "for i in range(7):\n",
    "    most_similar(i,pairwise_similarities,'Cosine Similarity')\n",
    "    print(\"---\")\n",
    "    #most_similar(0,pairwise_differences,'Euclidean Distance')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save matrix as pickle\n",
    "with open(f'data/lyrec_similarity_mat_{sample_frac}.pkl', 'wb') as f:\n",
    "    np.save(f, pairwise_similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
