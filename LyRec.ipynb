{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm().pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num rows 5162\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn \n",
    "import matplotlib.pyplot as plt\n",
    "from ftfy import fix_text\n",
    "import threading\n",
    "import os\n",
    "\n",
    "filename = 'fulldataset.csv'\n",
    "sample_frac = 0.01\n",
    "\n",
    "df = pd.read_csv(filename,quotechar=\"\\\"\")\n",
    "df = df.sample(frac=sample_frac, random_state=1)\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "num_rows = len(df.index)\n",
    "print(\"num rows\", num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning dataset, no cache available\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aa514031d5b4030a96c6891dde90e47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5162.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Band</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Song</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reba McEntire</td>\n",
       "      <td>The greatest man I never knew lived just down ...</td>\n",
       "      <td>The Greatest Man I Never Knew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vanessa Carlton</td>\n",
       "      <td>Stealing glances through the key hole\\nIn a br...</td>\n",
       "      <td>Hear the Bells</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Snoop Dogg</td>\n",
       "      <td>What it do,\\nComing at you live, it's your boy...</td>\n",
       "      <td>Pronto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Snoop Dogg</td>\n",
       "      <td>Another smoke session up in this motherfucker\\...</td>\n",
       "      <td>Buss 'N Rocks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Shirelles</td>\n",
       "      <td>Everybody, twist\\n\\nThey're twisting in Clevel...</td>\n",
       "      <td>Twisting USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5157</th>\n",
       "      <td>Asia</td>\n",
       "      <td>Whenever your shadow falls on stony ground\\nAn...</td>\n",
       "      <td>Wherever You Are</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5158</th>\n",
       "      <td>John Prine</td>\n",
       "      <td>I got kicked off Noah's Ark\\nI turn my cheek t...</td>\n",
       "      <td>Sweet Revenge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5159</th>\n",
       "      <td>Travis</td>\n",
       "      <td>In the church one day you will get hurt\\nIn th...</td>\n",
       "      <td>Some Sad Song</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5160</th>\n",
       "      <td>4 Strings</td>\n",
       "      <td>The waves are rolling in\\nI can smell the sea\\...</td>\n",
       "      <td>All Around the World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5161</th>\n",
       "      <td>Sal Mosca</td>\n",
       "      <td>Never thought I'd fall,\\nBut now I hear love c...</td>\n",
       "      <td>I'm Getting Sentimental over You</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5162 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Band                                             Lyrics  \\\n",
       "0       Reba McEntire  The greatest man I never knew lived just down ...   \n",
       "1     Vanessa Carlton  Stealing glances through the key hole\\nIn a br...   \n",
       "2          Snoop Dogg  What it do,\\nComing at you live, it's your boy...   \n",
       "3          Snoop Dogg  Another smoke session up in this motherfucker\\...   \n",
       "4       The Shirelles  Everybody, twist\\n\\nThey're twisting in Clevel...   \n",
       "...               ...                                                ...   \n",
       "5157             Asia  Whenever your shadow falls on stony ground\\nAn...   \n",
       "5158       John Prine  I got kicked off Noah's Ark\\nI turn my cheek t...   \n",
       "5159           Travis  In the church one day you will get hurt\\nIn th...   \n",
       "5160        4 Strings  The waves are rolling in\\nI can smell the sea\\...   \n",
       "5161        Sal Mosca  Never thought I'd fall,\\nBut now I hear love c...   \n",
       "\n",
       "                                  Song  \n",
       "0        The Greatest Man I Never Knew  \n",
       "1                       Hear the Bells  \n",
       "2                               Pronto  \n",
       "3                        Buss 'N Rocks  \n",
       "4                         Twisting USA  \n",
       "...                                ...  \n",
       "5157                  Wherever You Are  \n",
       "5158                     Sweet Revenge  \n",
       "5159                     Some Sad Song  \n",
       "5160              All Around the World  \n",
       "5161  I'm Getting Sentimental over You  \n",
       "\n",
       "[5162 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle_filename = f\"lyrec_df_{sample_frac}.pkl\"\n",
    "if os.path.isfile(pickle_filename):\n",
    "    print(\"Found pickle file for current config, using that\")\n",
    "    df = pd.read_pickle(file_name)\n",
    "else:\n",
    "    print(\"Cleaning dataset, no cache available\")\n",
    "    pbar = tqdm(total=(num_rows))\n",
    "    def clean(df, row):\n",
    "        try:\n",
    "            lyric = fix_text(df['Lyrics'][row])\n",
    "            band = fix_text(df['Band'][row])\n",
    "            song = fix_text(df['Song'][row])\n",
    "            df['Lyrics'][row] = lyric\n",
    "            df['Band'][row] = band\n",
    "            df['Song'][row] = song\n",
    "        except Exception:\n",
    "            print(\"Error cleaning up row:\", row,\"dropping instead\")\n",
    "            df.drop(index=row)\n",
    "        pbar.update(1)\n",
    "\n",
    "    threads = []\n",
    "    for row in df.index:\n",
    "        t = threading.Thread(target=clean, args=(df, row))\n",
    "        t.start()\n",
    "        threads.append(t)\n",
    "\n",
    "    for t in threads:\n",
    "        t.join()\n",
    "\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataset to pickle\n",
    "df.to_pickle(pickle_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt at BERT pairwise similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d89f0045b9c4a409c666acf840f3bbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Batches'), FloatProgress(value=0.0, max=162.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "sbert_model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "document_embeddings = None\n",
    "if os.path.isfile(f'lyrec_embeddings_{sample_frac}.pkl'):\n",
    "    print(\"Using existing pickle\")\n",
    "    with open(f'lyrec_embeddings_{sample_frac}.pkl', 'wb') as f:\n",
    "        document_embeddings = numpy.load(f)\n",
    "else:\n",
    "    document_embeddings = sbert_model.encode(df['Lyrics'], show_progress_bar=True, device=\"cpu\")\n",
    "# document_embeddingsing difficulty using/installing this library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'lyrec_embeddings_{sample_frac}.pkl', 'wb') as f:\n",
    "    np.save(f, document_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5162, 768)\n",
      "Song: The Greatest Man I Never Knew - Reba McEntire\n",
      "\n",
      "\n",
      "Similar Songs:\n",
      "\n",
      "\n",
      "Similar Song: The Greatest Man I Never Knew - Reba McEntire\n",
      "Cosine Similarity : 1.0\n",
      "\n",
      "\n",
      "Similar Song: Bonny - Prefab Sprout\n",
      "Cosine Similarity : 0.8753452301025391\n",
      "\n",
      "\n",
      "Similar Song: Chatting Today - Thin Lizzy\n",
      "Cosine Similarity : 0.8715394735336304\n",
      "\n",
      "\n",
      "Similar Song: A Most Peculiar Man [Live] - Simon & Garfunkel\n",
      "Cosine Similarity : 0.8692291975021362\n",
      "\n",
      "\n",
      "Similar Song: Almost Said Goodbye [DVD] - Peter Frampton\n",
      "Cosine Similarity : 0.8509968519210815\n",
      "---\n",
      "Song: The Greatest Man I Never Knew - Reba McEntire\n",
      "\n",
      "\n",
      "Similar Songs:\n",
      "\n",
      "\n",
      "Similar Song: The Greatest Man I Never Knew - Reba McEntire\n",
      "Euclidean Distance : 0.0\n",
      "\n",
      "\n",
      "Similar Song: Bonny - Prefab Sprout\n",
      "Euclidean Distance : 7.809667110443115\n",
      "\n",
      "\n",
      "Similar Song: Chatting Today - Thin Lizzy\n",
      "Euclidean Distance : 8.06407642364502\n",
      "\n",
      "\n",
      "Similar Song: A Most Peculiar Man [Live] - Simon & Garfunkel\n",
      "Euclidean Distance : 8.12240982055664\n",
      "\n",
      "\n",
      "Similar Song: Almost Said Goodbye [DVD] - Peter Frampton\n",
      "Euclidean Distance : 8.635895729064941\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import pairwise\n",
    "print(document_embeddings.shape)\n",
    "pairwise_similarities=pairwise.cosine_similarity(document_embeddings)\n",
    "pairwise_differences=pairwise.euclidean_distances(document_embeddings)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "\n",
    "tfidfvectoriser=TfidfVectorizer()\n",
    "tfidfvectoriser.fit(df.Lyrics)\n",
    "tfidf_vectors=tfidfvectoriser.transform(df.Lyrics)\n",
    "\n",
    "def most_similar(doc_id,similarity_matrix,matrix):\n",
    "    print (f'Song: {df.iloc[doc_id][\"Song\"]} - {df.iloc[doc_id][\"Band\"]}')\n",
    "    print ('\\n')\n",
    "    print ('Similar Songs:')\n",
    "    if matrix=='Cosine Similarity':\n",
    "        similar_ix=np.argsort(similarity_matrix[doc_id])[::-1]\n",
    "    elif matrix=='Euclidean Distance':\n",
    "        similar_ix=np.argsort(similarity_matrix[doc_id])\n",
    "    for ix in similar_ix[:5]:\n",
    "#         if ix==doc_id:\n",
    "#             continue\n",
    "        print('\\n')\n",
    "        print (f'Similar Song: {df.iloc[ix][\"Song\"]} - {df.iloc[ix][\"Band\"]}')\n",
    "        print (f'{matrix} : {similarity_matrix[doc_id][ix]}')\n",
    "\n",
    "most_similar(0,pairwise_similarities,'Cosine Similarity')\n",
    "print(\"---\")\n",
    "most_similar(0,pairwise_differences,'Euclidean Distance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/george/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/george/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'love': 73729, 'know': 58822, 'like': 55336, 'got': 51522, 'oh': 51155, 'na': 40133, 'get': 38660, 'one': 36915, 'go': 36237, 'que': 35033, 'time': 34482, 'la': 33735, 'let': 33129, 'see': 32970, 'baby': 32736, 'never': 31985, 'want': 30519, 'come': 29883, 'de': 29258, 'yeah': 28277, 'way': 26474, 'say': 26126, 'cause': 25475, 'make': 25312, 'back': 23866, 'take': 23324, 'gon': 22378, 'heart': 22250, 'life': 21894, 'away': 20811, 'day': 20372, 'feel': 20075, 'night': 19821, 'right': 19090, 'man': 19002, 'could': 18932, 'tell': 18332, 'need': 17837, 'world': 16843, 'give': 16365, 'good': 16024, 'girl': 16003, 'little': 15752, 'think': 14813, 'well': 14719, 'still': 14128, 'un': 13877, 'keep': 13800, 'long': 13786, 'en': 13736, 'ya': 13674, 'tu': 13622, 'eyes': 13622, 'te': 13539, 'around': 13510, 'every': 13347, 'look': 13235, 'wan': 13120, 'said': 12964, 'el': 12636, 'would': 12469, 'us': 12271, 'find': 12222, 'home': 12097, 'ever': 11897, 'mind': 11876, 'yo': 11797, 'always': 11566, 'hey': 11111, 'mi': 11049, 'nothing': 10556, 'gone': 10537, 'chorus': 10512, 'ta': 10491, 'things': 10470, 'die': 10453, 'better': 10345, 'hear': 10132, 'hold': 9958, 'se': 9891, 'es': 9666, 'le': 9649, 'old': 9384, 'ich': 9185, 'much': 9079, 'everything': 9014, 'new': 8889, 'really': 8717, 'believe': 8665, 'thing': 8651, 'alone': 8544, 'live': 8524, 'something': 8383, 'stay': 8319, 'try': 8315, 'leave': 8297, 'light': 8289, 'put': 8269, 'call': 8234, 'made': 8099}\n",
      "[[0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 2. 5. ... 1. 0. 0.]\n",
      " ...\n",
      " [6. 0. 0. ... 0. 0. 0.]\n",
      " [1. 2. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "Song: The Greatest Man I Never Knew - Reba McEntire\n",
      "Similar Songs:\n",
      "\n",
      "\n",
      "Similar Song: The Greatest Man I Never Knew - Reba McEntire\n",
      "Cosine Similarity : 0.9999999999999994\n",
      "\n",
      "\n",
      "Similar Song: A Feeling Is - The Emotions\n",
      "Cosine Similarity : 0.8652367093857665\n",
      "\n",
      "\n",
      "Similar Song: Never Dead - Megadeth\n",
      "Cosine Similarity : 0.8424931307209076\n",
      "\n",
      "\n",
      "Similar Song: Never Relaxed - Daniel Johnston\n",
      "Cosine Similarity : 0.839834710357086\n",
      "\n",
      "\n",
      "Similar Song: You'll Never Thirst - Juanita Bynum\n",
      "Cosine Similarity : 0.839052243539667\n",
      "---\n",
      "Song: The Greatest Man I Never Knew - Reba McEntire\n",
      "Similar Songs:\n",
      "\n",
      "\n",
      "Similar Song: The Greatest Man I Never Knew - Reba McEntire\n",
      "Euclidean Distance : 0.0\n",
      "\n",
      "\n",
      "Similar Song: Never Dead - Megadeth\n",
      "Euclidean Distance : 5.830951894845301\n",
      "\n",
      "\n",
      "Similar Song: I'll Take a Melody - The U-Liners\n",
      "Euclidean Distance : 6.324555320336759\n",
      "\n",
      "\n",
      "Similar Song: Acid Again - Meat Beat Manifesto\n",
      "Euclidean Distance : 6.4031242374328485\n",
      "\n",
      "\n",
      "Similar Song: Crooked Man - Susan Ashton\n",
      "Euclidean Distance : 6.48074069840786\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "import re\n",
    "from operator import itemgetter\n",
    "from sklearn.metrics import pairwise\n",
    "# Define dictionary utility function\n",
    "BAG_SIZE = 100\n",
    "def get_top_values(d,N = BAG_SIZE):\n",
    "    return list(sorted(d.items(), key = itemgetter(1), reverse = True)[:N])\n",
    "\n",
    "# Preprocess songs\n",
    "\n",
    "# set stop words in english\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "# creating  \"master\" dictionary\n",
    "word2count = {}\n",
    "\n",
    "for row in df.index:\n",
    "    song = df['Lyrics'][row]\n",
    "\n",
    "    # remove stopwords and clean up each song\n",
    "    song = song.lower()\n",
    "    song = re.sub(r'\\W', ' ', song)\n",
    "    song = re.sub(r'\\s+', ' ', song)\n",
    "    song = re.sub(r'\\r|\\n', ' ', song)\n",
    "\n",
    "    words = nltk.word_tokenize(song)\n",
    "    for word in words:\n",
    "\n",
    "        if word not in stop_words:\n",
    "\n",
    "            if word not in word2count.keys():\n",
    "                word2count[word] = 1\n",
    "            else:\n",
    "                word2count[word] += 1\n",
    "\n",
    "word2count_list = get_top_values(word2count)\n",
    "word2count = dict(word2count_list)\n",
    "word_ranks = {w2c[0]: r for r, w2c in enumerate(word2count_list)}\n",
    "\n",
    "# Now pass through again and create vectors\n",
    "\n",
    "song_counts = np.zeros([num_rows, BAG_SIZE])\n",
    "\n",
    "for song_index in df.index:\n",
    "\n",
    "    song = df['Lyrics'][song_index]\n",
    "\n",
    "    # remove stopwords and clean up each song\n",
    "    song = song.lower()\n",
    "    song = re.sub(r'\\W', ' ', song)\n",
    "    song = re.sub(r'\\s+', ' ', song)\n",
    "    song = re.sub(r'\\r|\\n', ' ', song)\n",
    "\n",
    "    words = nltk.word_tokenize(song)\n",
    "    for word in words:\n",
    "        if word in word_ranks:\n",
    "            word_idx = word_ranks[word]\n",
    "            song_counts[song_index][word_idx] += 1\n",
    "\n",
    "print(word2count)\n",
    "print(song_counts)\n",
    "\n",
    "\n",
    "pairwise_similarities=pairwise.cosine_similarity(song_counts)\n",
    "# pairwise_differences=pairwise.euclidean_distances(song_counts)\n",
    "\n",
    "\n",
    "def most_similar(doc_id,similarity_matrix,matrix):\n",
    "    print (f'Song: {df.iloc[doc_id][\"Song\"]} - {df.iloc[doc_id][\"Band\"]}')\n",
    "    print ('Similar Songs:')\n",
    "    \n",
    "    if matrix=='Cosine Similarity':\n",
    "        similar_ix=np.argsort(similarity_matrix[doc_id])[::-1]\n",
    "    elif matrix=='Euclidean Distance':\n",
    "        similar_ix=np.argsort(similarity_matrix[doc_id])\n",
    "    for ix in similar_ix[:5]:\n",
    "#         if ix==doc_id:\n",
    "#             continue\n",
    "        print('\\n')\n",
    "        print (f'Similar Song: {df.iloc[ix][\"Song\"]} - {df.iloc[ix][\"Band\"]}')\n",
    "        print (f'{matrix} : {similarity_matrix[doc_id][ix]}')\n",
    "            \n",
    "most_similar(0,pairwise_similarities,'Cosine Similarity')\n",
    "print(\"---\")\n",
    "# most_similar(0,pairwise_differences,'Euclidean Distance')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save matrix as pickle\n",
    "with open(f'lyrec_similarity_mat_{sample_frac}.pkl', 'wb') as f:\n",
    "    np.save(f, pairwise_similarities)\n",
    "# with open(f'lyrec_differences_mat_{sample_frac}.pkl', 'wb') as f:\n",
    "#     np.save(f, pairwise_similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
